{
    "title": "Plenoxels: Radiance Fields Without Neural Networks",
    "authors": ["Alex Yu*", "Sara Fridovich-Keil*", "Matt Tancik",
        "Qinhong Chen", "Benjamin Recht", "Angjoo Kanazawa"
    ],
    "venue": "CVPR 2022",
    "award": "Oral",
    "arxiv_link": "https://arxiv.org/abs/2112.05131",
    "web_link": "/plenoxels",
    "wiki_link": "https://en.wikipedia.org/wiki/Neural_radiance_field#Plenoxels",
    "video_link": "https://www.youtube.com/watch?v=ElnuwpQEqTA&feature=emb_title",
    "two_minute_link": "https://www.youtube.com/watch?v=yptwRRpPEBM", 
    "image": "img/plenoxels.gif",
    "abstract": "We introduce Plenoxels (plenoptic voxels), a system for photorealistic view synthesis. Plenoxels represent a scene as a sparse 3D grid with spherical harmonics. This representation can be optimized from calibrated images via gradient methods and regularization without any neural components. On standard, benchmark tasks, Plenoxels are optimized two orders of magnitude faster than Neural Radiance Fields with no loss in visual quality."
}
